{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca71e1-4eeb-445f-aa27-1cbdae8a23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dadk.QUBOSolverCPU import *\n",
    "from dadk.BinPol import *\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d015a1ae",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data \n",
    "\n",
    "# Assets\n",
    "asset_quantity = pd.read_csv(\"data/sample_asset_quantity.csv\", header=None)[0].values.tolist()\n",
    "asset_value = pd.read_csv(\"data/sample_asset_value.csv\", header=None)[0].values.tolist()\n",
    "asset_tiers = pd.read_csv(\"data/sample_asset_tiers.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_assets = len(asset_quantity)\n",
    "\n",
    "# Accounts \n",
    "account_exposure = pd.read_csv(\"data/sample_account_exposure.csv\", header=None)[0].values.tolist()\n",
    "account_duration = pd.read_csv(\"data/sample_account_duration.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_accounts = len(account_exposure)\n",
    "\n",
    "# Haircuts\n",
    "haircuts = (pd.read_csv(\"data/sample_haircuts.csv\", header=None).values.tolist())\n",
    "\n",
    "#Single Limits\n",
    "single_limits = (pd.read_csv(\"data/sample_single_limits.csv\", header=None).values.tolist())\n",
    "\n",
    "# Updated Tier list \n",
    "cost_factor_matrix = np.zeros(shape=(n_assets, n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        cost_factor_matrix[i,j] = abs(account_duration[j] - asset_tiers[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55bc0877",
   "metadata": {},
   "source": [
    " ## Penalty Terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty terms\n",
    "lambda_cost_fn = 1e5\n",
    "lambda_consistency1, lambda_consistency2 = 1, 1\n",
    "lambda_exposure1, lambda_exposure2 = 1, 5e2\n",
    "\n",
    "#lambda_single_lim1, lambda_single_lim2 = 1,1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95a2f861",
   "metadata": {},
   "source": [
    "# Constructing the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beae6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-bit binary variables\n",
    "n_binary = 7\n",
    "binary_coeff = []\n",
    "max_binary_value = (2**n_binary) - 1\n",
    "\n",
    "for b in range(1,n_binary+1):\n",
    "    aux_term = (2**(b-1) * 1) / max_binary_value\n",
    "    binary_coeff.append(aux_term)\n",
    "\n",
    "single_limits_fractional = np.zeros_like(single_limits) \n",
    "single_limits_num_bits = np.zeros((n_assets,n_accounts), dtype=int) \n",
    "\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        single_limits_fractional[i][j] = single_limits[i][j]/asset_quantity[i]\n",
    "        aux_variable = int(np.floor(np.log2((single_limits_fractional[i][j])*max_binary_value)))\n",
    "        single_limits_num_bits[i][j] = n_binary if aux_variable > n_binary else aux_variable\n",
    "\n",
    "binary_variables = []\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        binary_variables.append(BitArrayShape(name=f'bin_vars{i},{j}', shape=(1, 1, single_limits_num_bits[i][j]), axis_names=['Asset', 'Account', 'Binary']))\n",
    "\n",
    "\n",
    "var_shape_set = VarShapeSet(*binary_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing QUBO equation\n",
    "\n",
    "# Objective function\n",
    "scale_cost_fn = 1000\n",
    "\n",
    "# Objective function\n",
    "cost_function = BinPol(var_shape_set)\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            cost_function.add_term(cost_factor_matrix[i][j]*binary_coeff[k],((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "cost_function.multiply_scalar(scale_cost_fn)\n",
    "print(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9375bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#consistency requirement\n",
    "con1 = BinPol(var_shape_set)\n",
    "con2 = BinPol(var_shape_set)\n",
    "scale_con1 = 1000\n",
    "scale_con2 = 100000\n",
    "\n",
    "con_constraint = BinPol(var_shape_set)\n",
    "for i in range(n_assets):\n",
    "    aux_term = BinPol(var_shape_set)\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term.add_term(binary_coeff[k],((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "        aux_term.add_term(-1,())\n",
    "    con1.add(aux_term)\n",
    "    aux_term.power(2)\n",
    "    con2.add(aux_term)\n",
    "verify_con = con1 + con2\n",
    "\n",
    "\n",
    "con1.multiply_scalar(lambda_consistency1)\n",
    "con2.multiply_scalar(lambda_consistency2)\n",
    "\n",
    "\n",
    "\n",
    "con_constraint = con1*scale_con1 + con2*scale_con2\n",
    "print(con_constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exposure requirements\n",
    "exposure1  = BinPol(var_shape_set)\n",
    "exposure2 = BinPol(var_shape_set)\n",
    "scale_exposure1 = 1e4\n",
    "scale_exposure2 = 1e7\n",
    "norm_exposure = max(np.array(asset_quantity)*np.array(asset_value))*64/max_binary_value\n",
    "\n",
    "for j in range(n_accounts):\n",
    "    aux_term = BinPol(var_shape_set)\n",
    "    for i in range(n_assets):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term.add_term(binary_coeff[k]*asset_quantity[i]*asset_value[i]*haircuts[i][j]/100,((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "    aux_term.add_term(-account_exposure[j],())\n",
    "    exposure1.add(aux_term)\n",
    "    aux_term.power(2)\n",
    "    exposure2.add(aux_term)\n",
    "\n",
    "verify_exposure = -exposure1 + exposure2\n",
    "\n",
    "exposure1.multiply_scalar(lambda_exposure1)\n",
    "exposure2.multiply_scalar(lambda_exposure2)\n",
    "\n",
    "\n",
    "\n",
    "exposure_requirements = -exposure1*scale_exposure1/norm_exposure + exposure2*scale_exposure2/(norm_exposure**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final QUBO\n",
    "final_equation = (cost_function*lambda_cost_fn + con_constraint + exposure_requirements)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a32148",
   "metadata": {},
   "source": [
    "# Run Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QUBOSolverCPU(\n",
    "   \n",
    "    number_iterations    = 50000,               # total number of itrations per run\n",
    "    number_runs          = 4,                 # number of stochastically independant runs\n",
    "    temperature_start    = 5000,               # start temperature for annealing as float value\n",
    "    temperature_end      = 10,                 # end temperature for annealing as float value \n",
    "    temperature_mode     = 0,                         # 0: reduce temperature by factor (1-temperature_decay) every temperature_interval steps\n",
    "                                                      # 1: reduce temperature by factor (1-temperature_decay*temperature) every temperature_interval steps\n",
    "                                                      # 2: reduce temperature by factor (1-temperature_decay*temperature^2) every temperature_interval steps\n",
    "    temperature_decay    = 0.0095,             # see temperature_mode 0\n",
    "    temperature_interval = 1,                  # see temperature_mode 0\n",
    "    offset_increase_rate = 5000.0,             # increase of dynamic offset when no bit selected, set to 0.0 to switch off dynamic offset\n",
    "    graphics             = True                # create data for graphics output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de356258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run solver\n",
    "start=datetime.now()\n",
    "solution_list = solver.minimize(final_equation)\n",
    "\n",
    "# Get results\n",
    "solution = solution_list.get_minimum_energy_solution()\n",
    "configuration = solution.configuration\n",
    "print(\"Cost function:\", cost_function.compute(configuration)/1000)\n",
    "print(\"Consistency constraint:\",verify_con.compute(configuration))\n",
    "print(\"Exposure:\", verify_exposure.compute(configuration))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1655ecb",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bit_array = []\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        my_bit_array.append(solution.extract_bit_array(f\"bin_vars{i},{j}\"))\n",
    "\n",
    "\n",
    "exposure_solution = np.zeros(shape = (n_accounts))\n",
    "allocation_solution = np.zeros(shape = (n_assets))\n",
    "\n",
    "print(\"=====Each Individual Allocation Percentage and Verification of Single Limits=====\")\n",
    "counter = 0\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            bit += str(my_bit_array[counter][0][0][k])\n",
    "            decimal +=(2**k)*my_bit_array[counter][0][0][k]\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        print(f\"Assign {decimal*(100/max_binary_value):0.2f}% of asset {i+1} to account {j+1}\")\n",
    "        if (decimal/max_binary_value)*asset_quantity[i] > single_limits[i][j]: \n",
    "            print(f\"Single limit constraint satisfied: {((decimal/max_binary_value)*asset_quantity[i]) <= single_limits[i][j]}\")\n",
    "            print(f\"Quantity assigned = {(decimal/max_binary_value)*asset_quantity[i]:0.2f}, Single limit is {single_limits[i][j]:0.2f}\")\n",
    "        exposure_solution[j] += (decimal /max_binary_value) * asset_value[i] * asset_quantity[i]*haircuts[i][j]/100\n",
    "        counter += 1\n",
    "    allocation_solution[i] = asset\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e64b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====Validation for Consistency====\")\n",
    "for i in range(n_assets):\n",
    "    print(f\"{allocation_solution[i]:0.2f}% of asset {i+1} posted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38146a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====Validation for Exposure======\")\n",
    "for i in range(n_accounts):\n",
    "    print(f\"${exposure_solution[i]:,} of collateral posted, ${account_exposure[i],:} required\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b645bbd5",
   "metadata": {},
   "source": [
    "# Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6cc41-348a-424a-8857-5bc5f92885b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv\n",
    "\n",
    "Q_value_unbalanced_fujitsu = np.zeros(shape=(n_assets,n_accounts))\n",
    "\n",
    "counter = 0\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            bit += str(my_bit_array[counter][0][0][k])\n",
    "            decimal +=binary_coeff[k]*my_bit_array[counter][0][0][k]*max_binary_value\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        Q_value_unbalanced_fujitsu[i][j] = decimal/max_binary_value\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "#print(Q_value_unbalanced_fujitsu)\n",
    "print(f\"Objective value: {sum(sum(Q_value_unbalanced_fujitsu*cost_factor_matrix))}\")\n",
    "#Uncomment the line below to save the Data to csv\n",
    "\n",
    "# pd.DataFrame(Q_value_unbalanced_py_qubo).to_csv(\"Q_value_unbalanced_fujitsu_no_single_lim3.csv\", header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
