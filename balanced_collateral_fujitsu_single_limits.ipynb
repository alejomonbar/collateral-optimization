{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dadk.QUBOSolverCPU import *\n",
    "from dadk.BinPol import *\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assets\n",
    "asset_quantity = pd.read_csv(\"data/sample_asset_quantity.csv\", header=None)[0].values.tolist()\n",
    "asset_value = pd.read_csv(\"data/sample_asset_value.csv\", header=None)[0].values.tolist()\n",
    "asset_tiers = pd.read_csv(\"data/sample_asset_tiers.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_assets = len(asset_quantity)\n",
    "\n",
    "# Accounts \n",
    "account_exposure = pd.read_csv(\"data/sample_account_exposure.csv\", header=None)[0].values.tolist()\n",
    "account_duration = pd.read_csv(\"data/sample_account_duration.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_accounts = len(account_exposure)\n",
    "\n",
    "# Haircuts \n",
    "haircuts = (pd.read_csv(\"data/sample_haircuts.csv\", header=None).values.tolist())\n",
    "\n",
    "#Single Limits\n",
    "single_limits = (pd.read_csv(\"data/sample_single_limits.csv\", header=None).values.tolist())\n",
    "\n",
    "# Updated Tier list \n",
    "cost_factor_matrix = np.zeros(shape=(n_assets, n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        cost_factor_matrix[i,j] = abs(account_duration[j] - asset_tiers[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty terms\n",
    "lambda_cost_fn = 1e6\n",
    "lambda_consistency = 1e1\n",
    "lambda_exposure = 3e2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-bit binary variables\n",
    "n_binary = 7\n",
    "max_binary_value = 2**(n_binary) - 1 \n",
    "\n",
    "binary_coeff_vector = np.zeros(n_binary)\n",
    "\n",
    "for i in range(n_binary):\n",
    "    binary_coeff_vector[i] = 2**i\n",
    "\n",
    "single_limits_fractional = np.zeros_like(single_limits)\n",
    "single_limits_num_bits = np.zeros((n_assets,n_accounts), dtype = int)\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        single_limits_fractional[i][j] = single_limits[i][j]/asset_quantity[i]\n",
    "        aux_variable = int(np.floor(np.log2(single_limits_fractional[i][j]*max_binary_value)))\n",
    "        single_limits_num_bits[i][j] = n_binary if aux_variable > n_binary else aux_variable\n",
    "\n",
    "\n",
    "binary_variables = []\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        binary_variables.append(BitArrayShape(name=f'bin_vars{i},{j}', shape=(1, 1, single_limits_num_bits[i][j]), axis_names=['Asset', 'Account', 'Binary']))\n",
    "\n",
    "\n",
    "consistency_slack_var = BitArrayShape(name='consistency_slack_var', shape=(n_assets, (int(np.ceil(np.log2(max_binary_value))))), axis_names=['Assets', 'Slack'])\n",
    "\n",
    "var_shape_set = VarShapeSet(binary_variables, consistency_slack_var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the QUBO equation\n",
    "This involves the QUBO objective function, the consistency contraints, the exposure constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUBO objective function \n",
    "cost_function = BinPol(var_shape_set)\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            cost_function.add_term(cost_factor_matrix[i][j]*binary_coeff_vector[k]/max_binary_value,((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "\n",
    "#scaling\n",
    "cost_function.multiply_scalar(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency constraint \n",
    "con_constraint = BinPol(var_shape_set)\n",
    "\n",
    "for i in range(n_assets):\n",
    "    aux_term = BinPol(var_shape_set)\n",
    "    consistency_penalty_slack = BinPol(var_shape_set)\n",
    "    #slack\n",
    "    for l in range((int(np.ceil(np.log2(max_binary_value))))):\n",
    "        consistency_penalty_slack.add_term(2**l,(('consistency_slack_var', i,l)))\n",
    "    #decision variable\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term.add_term(binary_coeff_vector[k],((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "    aux_term.add_term(-max_binary_value,()).add(consistency_penalty_slack)\n",
    "    aux_term.power(2)\n",
    "    con_constraint.add(aux_term)\n",
    "\n",
    "con_constraint.multiply_scalar(1/(2**((n_binary -1)*2)))\n",
    "con_constraint.multiply_scalar(1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exposure constraint\n",
    "\n",
    "exposure_penalty_term = BinPol(var_shape_set)\n",
    "\n",
    "for j in range(n_accounts):\n",
    "    aux_term1 = BinPol(var_shape_set)\n",
    "    for i in range(n_assets):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term1.add_term(binary_coeff_vector[k]*asset_quantity[i]*asset_value[i]*haircuts[i][j]/(100*max_binary_value),((f'bin_vars{i},{j}', 0, 0, k),))\n",
    "    aux_term1.add_term(-account_exposure[j],())\n",
    "    aux_term1.power(2)\n",
    "    exposure_penalty_term.add(aux_term1)\n",
    "    \n",
    "exposure_penalty_term.multiply_scalar(1/((max(np.array(asset_quantity)*np.array(asset_value))*64/max_binary_value)**2))\n",
    "exposure_penalty_term.multiply_scalar(1e8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final QUBO\n",
    "QUBO_equation = lambda_cost_fn*cost_function + lambda_consistency*con_constraint  + lambda_exposure*exposure_penalty_term "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define solver parameters\n",
    "solver = QUBOSolverCPU(\n",
    "   \n",
    "    number_iterations    = 50000,               # total number of itrations per run\n",
    "    number_runs          = 4,                 # number of stochastically independant runs\n",
    "    temperature_start    = 5000,               # start temperature for annealing as float value\n",
    "    temperature_end      = 10,                 # end temperature for annealing as float value \n",
    "    temperature_mode     = 0,                         # 0: reduce temperature by factor (1-temperature_decay) every temperature_interval steps\n",
    "                                                      # 1: reduce temperature by factor (1-temperature_decay*temperature) every temperature_interval steps\n",
    "                                                      # 2: reduce temperature by factor (1-temperature_decay*temperature^2) every temperature_interval steps\n",
    "    temperature_decay    = 0.0095,             # see temperature_mode 0\n",
    "    temperature_interval = 1,                  # see temperature_mode 0\n",
    "    offset_increase_rate = 5000.0,             # increase of dynamic offset when no bit selected, set to 0.0 to switch off dynamic offset\n",
    "    graphics             = True                # create data for graphics output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Solver\n",
    "start=datetime.now()\n",
    "solution_list = solver.minimize(QUBO_equation)\n",
    "\n",
    "#Get results\n",
    "solution = solution_list.get_minimum_energy_solution()\n",
    "configuration = solution.configuration\n",
    "\n",
    "\n",
    "print(\"Cost function:\", cost_function.compute(configuration))\n",
    "print(\"Consistency constraint:\", con_constraint.compute(configuration))\n",
    "print(\"Exposure:\", exposure_penalty_term.compute(configuration))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bit_array = []\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        my_bit_array.append(solution.extract_bit_array(f\"bin_vars{i},{j}\"))\n",
    "\n",
    "exposure_solution = np.zeros(shape = (n_accounts))\n",
    "allocation_solution = np.zeros(shape = (n_assets))\n",
    "\n",
    "\n",
    "\n",
    "print(\"=====Each Individual Allocation Percentage and Verification of Single Limits=====\")\n",
    "counter = 0\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            bit += str(my_bit_array[counter][0][0][k])\n",
    "            decimal +=(2**k)*my_bit_array[counter][0][0][k]\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        # print(f\"Assign {decimal*(100/max_binary_value):0.2f}% of asset {i+1} to account {j+1}\")\n",
    "        if (decimal/max_binary_value)*asset_quantity[i] > single_limits[i][j]: \n",
    "            print(f\"Single limit constraint satisfied: {((decimal/max_binary_value)*asset_quantity[i]) <= single_limits[i][j]}\")\n",
    "            print(f\"Quantity assigned = {(decimal/max_binary_value)*asset_quantity[i]:0.2f}, Single limit is {single_limits[i][j]:0.2f}\")\n",
    "        exposure_solution[j] += (decimal /max_binary_value) * asset_value[i] * asset_quantity[i]*haircuts[i][j]/100\n",
    "        counter += 1\n",
    "    allocation_solution[i] = asset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====Validation for Consistency====\")\n",
    "for i in range(n_assets):\n",
    "    print(f\"{allocation_solution[i]:0.2f}% of asset {i+1} posted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====Validation for Exposure======\")\n",
    "for i in range(n_accounts):\n",
    "    print(f\"${exposure_solution[i]:,} of collateral posted, ${account_exposure[i]} required. % Diff: {(exposure_solution[i]-account_exposure[i])*100/account_exposure[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print runtime\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv\n",
    "Q_value_balanced_fujitsu = np.zeros(shape=(n_assets,n_accounts))\n",
    "\n",
    "counter = 0\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            bit += str(my_bit_array[counter][0][0][k])\n",
    "            decimal +=binary_coeff_vector[k]*my_bit_array[counter][0][0][k]\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        Q_value_balanced_fujitsu[i][j] = decimal/max_binary_value\n",
    "        counter += 1\n",
    "\n",
    "print(Q_value_balanced_fujitsu)\n",
    "\n",
    "print(f\"Objective value: {sum(sum(Q_value_balanced_fujitsu*cost_factor_matrix))}\")\n",
    "\n",
    "#Uncomment the line below to save the Data to csv\n",
    "\n",
    "# pd.DataFrame(Q_value_balanced_fujitsu).to_csv(\"Q_value_balanced_fujitsu_no_single_lim_trial.csv\", header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsbc-optimisation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
