{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca71e1-4eeb-445f-aa27-1cbdae8a23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dadk.QUBOSolverCPU import *\n",
    "from dadk.BinPol import *\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d015a1ae",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data \n",
    "\n",
    "# Assets\n",
    "asset_quantity = pd.read_csv(\"data/sample_asset_quantity.csv\", header=None)[0].values.tolist()\n",
    "asset_value = pd.read_csv(\"data/sample_asset_value.csv\", header=None)[0].values.tolist()\n",
    "asset_tiers = pd.read_csv(\"data/sample_asset_tiers.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_assets = len(asset_quantity)\n",
    "\n",
    "# Accounts \n",
    "account_exposure = pd.read_csv(\"data/sample_account_exposure.csv\", header=None)[0].values.tolist()\n",
    "account_duration = pd.read_csv(\"data/sample_account_duration.csv\", header=None)[0].values.tolist()\n",
    "\n",
    "n_accounts = len(account_exposure)\n",
    "\n",
    "# Haircuts\n",
    "haircuts = (pd.read_csv(\"data/sample_haircuts.csv\", header=None).values.tolist())\n",
    "\n",
    "#Single Limits\n",
    "#single_limits = (pd.read_csv(\"data/sample_single_limits.csv\", header=None).values.tolist())\n",
    "\n",
    "# Updated Tier list \n",
    "cost_factor_matrix = np.zeros(shape=(n_assets, n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        cost_factor_matrix[i,j] = abs(account_duration[j] - asset_tiers[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55bc0877",
   "metadata": {},
   "source": [
    " ## Penalty Terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty terms\n",
    "lambda_cost_fn = 1e4\n",
    "lambda_consistency1, lambda_consistency2 = 1, 1\n",
    "lambda_exposure1, lambda_exposure2 = 1, 1e6\n",
    "\n",
    "#lambda_single_lim1, lambda_single_lim2 = 1,1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95a2f861",
   "metadata": {},
   "source": [
    "# Constructing the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beae6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-bit binary variables\n",
    "n_binary = 7\n",
    "binary_coeff = []\n",
    "max_binary_value = (2**n_binary) - 1\n",
    "\n",
    "for b in range(1,n_binary+1):\n",
    "    aux_term = (2**(b-1) * 1) / max_binary_value\n",
    "    binary_coeff.append(aux_term)\n",
    "\n",
    "binary_variables = VarShapeSet(BitArrayShape(name='bin_vars', shape=(n_assets, n_accounts, n_binary), axis_names=['Assets', 'Accounts', 'Binary']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing QUBO equation\n",
    "\n",
    "# Objective function\n",
    "cost_function = BinPol(binary_variables)\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(n_binary):\n",
    "            cost_function.add_term(cost_factor_matrix[i][j]*binary_coeff[k],((\"bin_vars\", i, j, k),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9375bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#consistency requirement\n",
    "con1 = BinPol(binary_variables)\n",
    "con2 = BinPol(binary_variables)\n",
    "\n",
    "con_constraint = BinPol(binary_variables)\n",
    "for i in range(n_assets):\n",
    "    aux_term = BinPol(binary_variables)\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(n_binary):\n",
    "            aux_term.add_term(binary_coeff[k],((\"bin_vars\", i, j, k),))\n",
    "        aux_term.add_term(-1,())\n",
    "    con1.add(aux_term)\n",
    "    aux_term.power(2)\n",
    "    con2.add(aux_term)\n",
    "\n",
    "con1.multiply_scalar(lambda_consistency1)\n",
    "con2.multiply_scalar(lambda_consistency2)\n",
    "\n",
    "con_constraint = con1 + con2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exposure requirements\n",
    "exposure1  = BinPol(binary_variables)\n",
    "exposure2 = BinPol(binary_variables)\n",
    "\n",
    "\n",
    "for j in range(n_accounts):\n",
    "    aux_term = BinPol(binary_variables)\n",
    "    for i in range(n_assets):\n",
    "        for k in range(n_binary):\n",
    "            aux_term.add_term(binary_coeff[k]*asset_quantity[i]*asset_value[i]*haircuts[i][j]/100,((\"bin_vars\", i, j, k),))\n",
    "    aux_term.add_term(-account_exposure[j],())\n",
    "    exposure1.add(aux_term)\n",
    "    aux_term.power(2)\n",
    "    exposure2.add(aux_term)\n",
    "\n",
    "exposure1.multiply_scalar(lambda_exposure1/(np.mean(np.array(asset_quantity)*np.array(asset_value))))\n",
    "exposure2.multiply_scalar(lambda_exposure2/(np.mean(np.array(asset_quantity)*np.array(asset_value))**2))\n",
    "\n",
    "exposure_requirements = -exposure1 + exposure2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #single_limits\n",
    "# single1 = BinPol(var_shape_set)\n",
    "# single2  = BinPol(var_shape_set)\n",
    "\n",
    "\n",
    "# for i in range(n_assets):\n",
    "#     for j in range(n_accounts):\n",
    "#         step = BinPol(var_shape_set)\n",
    "#         for k in range(nbit):\n",
    "#             step.add_term(binary_coeff[k]*asset_quantity[i],((\"bin_vars\", i, j, k),))\n",
    "#         step.add_term(-single_limits[i][j],())\n",
    "#         single1.add(step)\n",
    "#     step.power(2)\n",
    "# #         print(step)\n",
    "#     single2.add(step)\n",
    "# #     print(step)\n",
    "# #     print('--')\n",
    "        \n",
    "# single1.multiply_scalar(lambda_single_lim1)\n",
    "# single2.multiply_scalar(lambda_single_lim2)\n",
    "\n",
    "# single_limit = single1 + single2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final QUBO\n",
    "final_equation = (cost_function*lambda_cost_fn + con_constraint + exposure_requirements) #+ single_limit\n",
    "final_equation *= 1e4 #scaling factor to avoid rounding of smaller values\n",
    "#To include single limits into the qubo uncomment all lines refering to them and the additional validation below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a32148",
   "metadata": {},
   "source": [
    "# Run Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QUBOSolverCPU(\n",
    "   \n",
    "    number_iterations    = 50000,               # total number of itrations per run\n",
    "    number_runs          = 4,                 # number of stochastically independant runs\n",
    "    temperature_start    = 5000,               # start temperature for annealing as float value\n",
    "    temperature_end      = 10,                 # end temperature for annealing as float value \n",
    "    temperature_mode     = 0,                         # 0: reduce temperature by factor (1-temperature_decay) every temperature_interval steps\n",
    "                                                      # 1: reduce temperature by factor (1-temperature_decay*temperature) every temperature_interval steps\n",
    "                                                      # 2: reduce temperature by factor (1-temperature_decay*temperature^2) every temperature_interval steps\n",
    "    temperature_decay    = 0.0095,             # see temperature_mode 0\n",
    "    temperature_interval = 1,                  # see temperature_mode 0\n",
    "    offset_increase_rate = 5000.0,             # increase of dynamic offset when no bit selected, set to 0.0 to switch off dynamic offset\n",
    "    graphics             = True                # create data for graphics output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de356258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run solver\n",
    "start=datetime.now()\n",
    "solution_list = solver.minimize(final_equation)\n",
    "\n",
    "# Get results\n",
    "solution = solution_list.get_minimum_energy_solution()\n",
    "configuration = solution.configuration\n",
    "my_bit_array = solution.extract_bit_array(\"bin_vars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1655ecb",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstring = ''\n",
    "\n",
    "exposure_solution = np.zeros(shape = (n_accounts))\n",
    "allocation_solution = np.zeros(shape = (n_assets))\n",
    "\n",
    "print(\"=====Each Individual Allocation Percentage=====\")\n",
    "\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(n_binary):\n",
    "            bit += str(my_bit_array[i][j][k])\n",
    "            decimal +=(2**k)*my_bit_array[i][j][k]\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        print(f\"Assign {decimal*(100/max_binary_value):0.2f}% of asset {i+1} to account {j+1}\")\n",
    "        exposure_solution[j] += (decimal /max_binary_value) * asset_value[i] * asset_quantity[i]*haircuts[i][j]/100\n",
    "    allocation_solution[i] = asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e64b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====Validation for Consistency====\")\n",
    "for i in range(n_assets):\n",
    "    print(f\"{allocation_solution[i]:0.2f}% of asset {i+1} posted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38146a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====Validation for Exposure======\")\n",
    "for i in range(n_accounts):\n",
    "    print(f\"${exposure_solution[i]:,} of collateral posted, ${account_exposure[i],:} required\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(\"===Validation of Single limits =====\")\n",
    "# for i in range(n_assets):\n",
    "#     for j in range(n_accounts):\n",
    "#         decimal = 0\n",
    "#         for k in range(n_binary):\n",
    "#             decimal +=(2**k)*my_bit_array[i][j][k]\n",
    "#         allocation = (decimal/max_binary_value)*asset_quantity[i] \n",
    "#         print(f\"Amount allocated: {allocation:0.2f}. Single Limit: {single_limits[i][j]:0.2f}\")\n",
    "#         print(f\"Constraint Satisfied?: {allocation <= single_limits[i][j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The objective function is: {cost_function.compute(configuration)}\")\n",
    "print(\"The optimal objective function is: 0.4299816571359823\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b645bbd5",
   "metadata": {},
   "source": [
    "# Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6cc41-348a-424a-8857-5bc5f92885b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv\n",
    "\n",
    "Q_value_balanced_py_qubo = np.zeros(shape=(n_assets,n_accounts))\n",
    "\n",
    "\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(n_binary):\n",
    "            bit += str(my_bit_array[i][j][k])\n",
    "            decimal +=binary_coeff[k]*my_bit_array[i][j][k]*max_binary_value\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        Q_value_balanced_py_qubo[i][j] = decimal/max_binary_value\n",
    "\n",
    "#Uncomment the line below to save the Data to csv\n",
    "\n",
    "# pd.DataFrame(Q_value_balanced_py_qubo).to_csv(\"Q_value_unbalanced_fujitsu_no_single_lim3.csv\", header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
