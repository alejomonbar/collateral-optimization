{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyqubo import Binary\n",
    "import pyqubo\n",
    "import neal\n",
    "import matplotlib.pyplot as plt \n",
    "from sympy import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b835204e",
   "metadata": {},
   "source": [
    "## Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data \n",
    "\n",
    "\n",
    "#Assets\n",
    "asset_quantity = pd.read_csv(\"data/sample_asset_quantity.csv\", header=None)[0].to_numpy()\n",
    "asset_value = pd.read_csv(\"data/sample_asset_value.csv\", header=None)[0].to_numpy()\n",
    "asset_tiers = pd.read_csv(\"data/sample_asset_tiers.csv\", header=None)[0].to_numpy()\n",
    "\n",
    "n_assets = len(asset_quantity)\n",
    "\n",
    "#Accounts \n",
    "account_exposure = pd.read_csv(\"data/sample_account_exposure.csv\", header=None)[0].to_numpy()\n",
    "account_duration = pd.read_csv(\"data/sample_account_duration.csv\", header=None)[0].to_numpy()\n",
    "\n",
    "n_accounts = len(account_exposure)\n",
    "\n",
    "#haircuts \n",
    "haircuts = pd.read_csv(\"data/sample_haircuts.csv\", header=None).to_numpy()/100\n",
    "\n",
    "#Updated Tier list \n",
    "cost_factor_matrix = np.zeros(shape=(n_assets, n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        cost_factor_matrix[i,j] = abs(account_duration[j] - asset_tiers[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "745912c2",
   "metadata": {},
   "source": [
    "# Penalty Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b158701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Penalty Terms\n",
    "lambda_cost_fn = 1e5\n",
    "lambda_consistency = 1\n",
    "lambda_exposure = 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "929ffbd4",
   "metadata": {},
   "source": [
    "# Defining the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary variables\n",
    "\n",
    "n_binary = 7\n",
    "max_binary_value = 2**(n_binary) - 1 \n",
    "\n",
    "binary_coeff_vector = np.zeros(n_binary)\n",
    "\n",
    "for i in range(n_binary):\n",
    "    binary_coeff_vector[i] = 2**i\n",
    "\n",
    "\n",
    "#Decision variable\n",
    "\n",
    "binary_variables = []\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(n_binary):\n",
    "            globals()[\"x\" + str(i + 1) + str(j + 1) + str(k+1)] = Binary(\"x\" + str(i + 1) + str(j + 1) + str(k+1))\n",
    "            binary_variables.append(globals()[\"x\" + str(i + 1) + str(j + 1) + str(k + 1)])\n",
    "\n",
    "\n",
    "#Slack variable for consistency \n",
    "num_slack_consistency_arr = np.zeros(shape=(n_assets))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    num_slack_consistency_arr[i] = int(np.ceil(np.log2(max_binary_value)))\n",
    "\n",
    "\n",
    "consistency_slack_variables_arr = [] \n",
    "\n",
    "for count, i in enumerate(num_slack_consistency_arr): \n",
    "    consistency_slack_variables_arr.append(pyqubo.Array.create(\"consistency_asset\" + str(count + 1) + \"_slack\", shape = int(i), vartype = \"BINARY\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dba1036e",
   "metadata": {},
   "source": [
    "# Constructing the QUBO equation \n",
    "\n",
    "This involves the QUBO objective function, the consistency contraints, the exposure constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#QUBO objective function \n",
    "\n",
    "cost_fn = 0\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        aux_term1 = 0\n",
    "        for k in range(n_binary):\n",
    "            aux_term1 += binary_coeff_vector[k]* globals()[\"x\" + str(i + 1) + str(j + 1) + str(k+1)]\n",
    "        cost_fn += aux_term1*cost_factor_matrix[i][j]\n",
    "\n",
    "cost_fn /= max_binary_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency constraint \n",
    "\n",
    "consistency_penalty_term = 0\n",
    "\n",
    "#slack part\n",
    "consistency_penalty_slack = []\n",
    "\n",
    "for i in consistency_slack_variables_arr:\n",
    "    aux_term = 0\n",
    "    for exponent,j in enumerate(i):\n",
    "        aux_term += (2**exponent)*j\n",
    "    consistency_penalty_slack.append(aux_term)\n",
    "\n",
    "\n",
    "#decision variable part\n",
    "for i in range(n_assets):\n",
    "    aux_term2 = 0\n",
    "    for j in range(n_accounts):\n",
    "        aux_term1 = 0\n",
    "        for k in range(n_binary):\n",
    "            aux_term1 += binary_coeff_vector[k]* globals()[\"x\" + str(i + 1) + str(j + 1) + str(k+1)]\n",
    "        aux_term2 += (aux_term1)\n",
    "    consistency_penalty_term += (aux_term2 - max_binary_value + consistency_penalty_slack[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exposure constraint\n",
    "\n",
    "exposure_penalty_term = 0\n",
    "\n",
    "for j in range(n_accounts):\n",
    "    aux_term2 = 0\n",
    "    for i in range(n_assets):\n",
    "        aux_term1 = 0\n",
    "        for k in range(n_binary):\n",
    "            aux_term1 += binary_coeff_vector[k]* globals()[\"x\" + str(i + 1) + str(j + 1) + str(k+1)]\n",
    "        aux_term2 += (aux_term1*asset_quantity[i]*asset_value[i]*haircuts[i][j])/max_binary_value\n",
    "    exposure_penalty_term += (aux_term2 - account_exposure[j]) **2 \n",
    "\n",
    "exposure_penalty_term /= np.mean(asset_quantity*asset_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Final QUBO\n",
    "QUBO_equation =lambda_cost_fn*cost_fn + lambda_consistency*consistency_penalty_term  + lambda_exposure*exposure_penalty_term \n",
    "\n",
    "#compile model\n",
    "model = QUBO_equation.compile()\n",
    "qubo, offset = model.to_qubo()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0520251",
   "metadata": {},
   "source": [
    "# Run Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Solver\n",
    "\n",
    "bqm = model.to_bqm()\n",
    "sa = neal.SimulatedAnnealingSampler()\n",
    "num_reads = 100\n",
    "num_sweeps = 1000\n",
    "sampleset = sa.sample(bqm, num_reads=num_reads, num_sweeps=num_sweeps)\n",
    "\n",
    "#Get best sample\n",
    "decoded_samples = model.decode_sampleset(sampleset)\n",
    "best_sample = min(decoded_samples, key=lambda x: x.energy)\n",
    "results = best_sample.sample\n",
    "pprint(f\"The minimum energy is: {best_sample.energy}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "710dafdd",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure_solution = np.zeros(shape = (n_accounts))\n",
    "allocation_solution = np.zeros(shape = (n_assets))\n",
    "\n",
    "print(\"=====Each Individual Allocation Percentage=====\")\n",
    "\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        decimal = 0\n",
    "        for k in range(n_binary):\n",
    "            decimal +=binary_coeff_vector[k]*results.get(\"x\" + str(i + 1) + str(j + 1) + str(k+1))\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        print(f\"Assign {decimal*(100/max_binary_value):0.2f}% of asset {i+1} to account {j+1}\")\n",
    "        exposure_solution[j] += (decimal /max_binary_value) * asset_value[i] * asset_quantity[i]*haircuts[i][j]\n",
    "    allocation_solution[i] = asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====Validation for Consistency====\")\n",
    "for i in range(n_assets):\n",
    "    print(f\"{allocation_solution[i]:0.2f}% of asset {i+1} posted\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====Validation for Exposure======\")\n",
    "for i in range(n_accounts):\n",
    "    print(f\"${exposure_solution[i]:,} of collateral posted, ${account_exposure[i]:,} required\") \n",
    "    print(f\"{(exposure_solution[i]/account_exposure[i] - 1) *100.:0.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de9df13c",
   "metadata": {},
   "source": [
    "# Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to an array\n",
    "Q_value_balanced_py_qubo = np.zeros(shape=(n_assets,n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        decimal = 0\n",
    "        for k in range(n_binary):\n",
    "            decimal +=binary_coeff_vector[k]*results.get(\"x\" + str(i + 1) + str(j + 1) + str(k+1))\n",
    "        Q_value_balanced_py_qubo[i][j] = decimal/max_binary_value\n",
    "\n",
    "pprint(f\"Objective value: {sum(sum(Q_value_balanced_py_qubo*cost_factor_matrix))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment line below to save file to csv\n",
    "\n",
    "#pd.DataFrame(Q_value_balanced_py_qubo).to_csv(\"Q_value_balanced_py_qubo_no_single_lim1.csv\", header=None, index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "970cdd760a6554ff9d7b1b410a24af8e9d54e51044eda066095b1481daf8ae7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
