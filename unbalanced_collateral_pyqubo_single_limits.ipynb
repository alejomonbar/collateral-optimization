{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091ce51-4213-4549-a26b-f9162f0078a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyqubo import Binary\n",
    "import pyqubo\n",
    "import neal\n",
    "import matplotlib.pyplot as plt \n",
    "from sympy import *\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca2b79b1",
   "metadata": {},
   "source": [
    "## Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679805f-42d0-4baf-ad45-a55c135123af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "\n",
    "#Assets\n",
    "asset_quantity = pd.read_csv(\"data/sample_asset_quantity.csv\", header=None)[0].to_numpy()\n",
    "asset_value = pd.read_csv(\"data/sample_asset_value.csv\", header=None)[0].to_numpy()\n",
    "asset_tiers = pd.read_csv(\"data/sample_asset_tiers.csv\", header=None)[0].to_numpy()\n",
    "\n",
    "n_assets = len(asset_quantity)\n",
    "\n",
    "\n",
    "#Accounts \n",
    "account_exposure = pd.read_csv(\"data/sample_account_exposure.csv\", header=None)[0].to_numpy()\n",
    "account_duration = pd.read_csv(\"data/sample_account_duration.csv\", header=None)[0].to_numpy()\n",
    "\n",
    "n_accounts = len(account_exposure)\n",
    "\n",
    "#single limits\n",
    "single_limits = pd.read_csv(\"data/sample_single_limits.csv\", header=None).to_numpy() \n",
    "\n",
    "#haircuts \n",
    "haircuts = pd.read_csv(\"data/sample_haircuts.csv\", header=None).to_numpy()/100\n",
    "\n",
    "\n",
    "#Updated Tier list \n",
    "\n",
    "cost_factor_matrix = np.zeros(shape=(n_assets, n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        cost_factor_matrix[i,j] = abs(account_duration[j] - asset_tiers[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9edd09d",
   "metadata": {},
   "source": [
    "# Penalty Terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty Terms\n",
    "lambda_cost_fn = 1e4\n",
    "lambda_consistency1, lambda_consistency2 = 1, 1\n",
    "lambda_exposure1, lambda_exposure2 =1, 5e2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7d2b297",
   "metadata": {},
   "source": [
    "# Constructing the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3398be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_variables = []\n",
    "n_binary = 7\n",
    "max_binary_value = 2**n_binary - 1\n",
    "\n",
    "single_limits_fractional = np.zeros_like(single_limits) \n",
    "single_limits_num_bits = np.zeros((n_assets,n_accounts), dtype=int) \n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        single_limits_fractional[i][j] = single_limits[i][j]/asset_quantity[i]\n",
    "        aux_variable = int(np.floor(np.log2((single_limits_fractional[i][j])*max_binary_value)))\n",
    "        single_limits_num_bits[i][j] = n_binary if aux_variable > n_binary else aux_variable\n",
    "        \n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            globals()[\"x\" + str(i + 1) + str(j + 1) + str(k)] = Binary(\"x\" + str(i + 1) + str(j + 1) + str(k))\n",
    "            binary_variables.append(globals()[\"x\" + str(i + 1) + str(j + 1) + str(k)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cost_function = 0\n",
    "\n",
    "scale_cost_fn = 1000\n",
    "\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        aux_term = 0\n",
    "        coeff = (cost_factor_matrix[i][j])/ (max_binary_value)\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term += (2 ** (k % n_binary)) * globals()[\"x\" + str(i + 1) + str(j + 1) + str(k)] \n",
    "        cost_function += scale_cost_fn*lambda_cost_fn*coeff*aux_term\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_constraint = 0\n",
    "scale_consis_1 = 1000\n",
    "scale_consis_2 = 100000\n",
    "\n",
    "for i in range(n_assets):\n",
    "    aux_term1 = 0\n",
    "    aux_term2 = 0\n",
    "    for j in range(n_accounts):\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term1 += (2 ** (k % n_binary)) * globals()[\"x\" + str(i + 1) + str(j + 1) + str(k)]\n",
    "        aux_term2 = (aux_term1/(max_binary_value)) - 1\n",
    "    con_constraint += scale_consis_1*(lambda_consistency1 * aux_term2) + scale_consis_2*(lambda_consistency2 * (aux_term2**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure_term1 = 0\n",
    "exposure_term2 = 0\n",
    "for j in range(n_accounts):\n",
    "    aux_term2 = 0\n",
    "    aux_term3 = 0\n",
    "    for i in range(n_assets):\n",
    "        aux_term1 = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            aux_term1 += (2 ** (k % n_binary)) * globals()[\"x\" + str(i + 1) + str(j + 1) + str(k)]\n",
    "        aux_term2 += (aux_term1/max_binary_value) * asset_quantity[i] * asset_value[i] * haircuts[i][j]\n",
    "    aux_term3 += aux_term2 - account_exposure[j]\n",
    "    exposure_term1 += -lambda_exposure1 * aux_term3\n",
    "    exposure_term2 += lambda_exposure2 * (aux_term3 ** 2)\n",
    "\n",
    "\n",
    "norm_exposure = max(asset_quantity*asset_value)*64/max_binary_value\n",
    "scale_exposure_1 = 1e4\n",
    "scale_exposure_2 = 1e7\n",
    "\n",
    "exposure_requirements = scale_exposure_1*(exposure_term1/norm_exposure)  + scale_exposure_2*(exposure_term2/norm_exposure**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full QUBO\n",
    "\n",
    "final_equation = cost_function + con_constraint + exposure_requirements \n",
    "\n",
    "# Compile QUBO\n",
    "model = final_equation.compile()\n",
    "# Obtain the Q matrix\n",
    "qubo, offset = model.to_qubo()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a635588e",
   "metadata": {},
   "source": [
    "# Run Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "\n",
    "# Use solver to find solution\n",
    "bqm = model.to_bqm()\n",
    "sa = neal.SimulatedAnnealingSampler()\n",
    "sampleset = sa.sample(bqm, num_reads=100, num_sweeps = 1000)\n",
    "decoded_samples = model.decode_sampleset(sampleset)\n",
    "\n",
    "# Get results\n",
    "best_sample = min(decoded_samples, key=lambda x: x.energy)\n",
    "results = best_sample.sample\n",
    "print(f\"The minimum energy is: {best_sample.energy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c82329a3",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "exposure_solution = np.zeros(shape = (n_accounts))\n",
    "allocation_solution = np.zeros(shape = (n_assets))\n",
    "\n",
    "print(\"=====Each Individual Allocation Percentage and Verification of Single Limits=====\")\n",
    "\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            decimal +=(2**k)*results.get(\"x\" + str(i + 1) + str(j + 1) + str(k))\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        print(f\"Assign {decimal*(100/max_binary_value):0.2f}% of asset {i+1} to account {j+1}\")\n",
    "        exposure_solution[j] += (decimal /max_binary_value) * asset_value[i] * asset_quantity[i]*haircuts[i][j]\n",
    "    allocation_solution[i] = asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====Validation for Consistency====\")\n",
    "for i in range(n_assets):\n",
    "    print(f\"{allocation_solution[i]:0.2f}% of asset {i+1} posted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====Validation for Exposure======\")\n",
    "for i in range(n_accounts):\n",
    "    print(f\"${exposure_solution[i]:,} of collateral posted, ${account_exposure[i]} required\")\n",
    "    print(f\"{(exposure_solution[i]/account_exposure[i] - 1) *100.:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===Validation of Single limits =====\")\n",
    "for i in range(n_assets):\n",
    "    for j in range(n_accounts):\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            decimal +=(2**k)*results.get(\"x\" + str(i + 1) + str(j + 1) + str(k))\n",
    "        allocation = (decimal/max_binary_value)*asset_quantity[i] \n",
    "        print(f\"Amount allocated: {allocation:0.2f}. Single Limit: {single_limits[i][j]:0.2f}\")\n",
    "        print(f\"Constraint Satisfied?: {allocation <= single_limits[i][j]}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbaff7-da0c-43b7-aa1b-6f0e19d303d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2d6bb04",
   "metadata": {},
   "source": [
    "# Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to an array\n",
    "Q_value_unbalanced_py_qubo = np.zeros(shape=(n_assets,n_accounts))\n",
    "\n",
    "for i in range(n_assets):\n",
    "    asset = 0\n",
    "    for j in range(n_accounts):\n",
    "        bit = ''\n",
    "        decimal = 0\n",
    "        for k in range(single_limits_num_bits[i][j]):\n",
    "            bit += str(results.get(\"x\" + str(i + 1) + str(j + 1) + str(k)))\n",
    "            decimal +=(2**k)*results.get(\"x\" + str(i + 1) + str(j + 1) + str(k))\n",
    "        asset += decimal*(100/max_binary_value)\n",
    "        Q_value_unbalanced_py_qubo[i][j] = decimal/max_binary_value\n",
    "\n",
    "pprint(f\"Objective value: {sum(sum(Q_value_unbalanced_py_qubo*cost_factor_matrix))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment the last line when you are happy with the results\"\"\"\n",
    "\n",
    "#pd.DataFrame(Q_value_unbalanced_py_qubo).to_csv(\"Q_value_unbalanced_py_qubo_no_single_lim1.csv\", header=None, index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
